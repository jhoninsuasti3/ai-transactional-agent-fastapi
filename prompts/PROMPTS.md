# Registro de Prompts Utilizados

> **OBLIGATORIO**: Este documento registra TODOS los prompts utilizados durante el desarrollo del proyecto,
> tanto para asistencia de desarrollo (Claude) como para el sistema en producci√≥n (OpenAI).

**√öltima actualizaci√≥n**: 2025-01-21
**Versi√≥n del documento**: 1.0.0

---

## üìã √çndice

1. [Informaci√≥n General](#informaci√≥n-general)
2. [Prompts de Desarrollo - Claude](#prompts-desarrollo-claude)
3. [Prompts del Sistema - OpenAI](#prompts-sistema-openai)
4. [Comparaci√≥n y An√°lisis](#comparaci√≥n-y-an√°lisis)
5. [Optimizaciones de Tokens](#optimizaciones-de-tokens)
6. [Versionado de Prompts](#versionado-de-prompts)
7. [Ap√©ndices](#ap√©ndices)

---

## 1. Informaci√≥n General {#informaci√≥n-general}

### Prop√≥sito del Documento

Este documento cumple con el requisito obligatorio de la prueba t√©cnica de documentar todos los prompts utilizados.
Se divide en dos categor√≠as principales:

1. **Prompts de Desarrollo (Claude)**: Usados para asistencia en desarrollo, arquitectura, debugging
2. **Prompts del Sistema (OpenAI)**: Usados en producci√≥n para el agente conversacional

### Metodolog√≠a de Registro

Para cada prompt se documenta:
- **Contexto**: ¬øPor qu√© se us√≥ este prompt?
- **Fecha y hora**: Cu√°ndo se utiliz√≥
- **Prompt completo**: Texto exacto del prompt
- **Resultado**: Qu√© se obtuvo
- **Tokens estimados**: Consumo aproximado (cuando aplique)
- **Iteraciones**: Versiones anteriores y mejoras

### Herramientas Utilizadas

- **Claude Code** (Anthropic): Asistencia de desarrollo (este documento)
- **OpenAI API**: Sistema en producci√≥n
  - Modelos disponibles: gpt-4.1-mini, gpt-4.1-nano, gpt-5-mini, gpt-5-nano
  - Modelo seleccionado: **gpt-4.1-mini** (balance precio/rendimiento)

---

## 2. Prompts de Desarrollo - Claude {#prompts-desarrollo-claude}

> **Nota**: Claude se usa SOLO para desarrollo asistido, NO en producci√≥n.
> No consume la API Key de OpenAI proporcionada.

### 2.1 An√°lisis Inicial y Planificaci√≥n

#### 2.1.1 An√°lisis de Requerimientos

**Fecha**: 2025-01-21 [Hora inicial]
**Contexto**: An√°lisis exhaustivo de la prueba t√©cnica y generaci√≥n del plan de trabajo

**Prompt**:
```
Seras mi asistente para el desarrollo de la prueba que te voy a pasar, el LLm sera
open ai porque asi lo eligieron cuando me compartieron el reto, de momento solo haz
un analisis, actua como un experto en desarrollo de software, en ai, en agentes y
arquitectura de software, y devops.

Quiero que me entregues un plan detallado, te voy a pasar tambien un proyecto que es
un poco viejo para el desarrollo de este tipo de sistemas que esta en la raiz con el
nombre de /home/jhonmo/apps/retos/ai-transactional-agent-fastapi/api-gabi-logic,
ademas te paso contexto que genere con herramientas y tools diferentes a anthropic o
claude, tambien podrian ser utiles
(/home/jhonmo/apps/retos/ai-transactional-agent-fastapi/docs/CONTEXTO.md) y en
general toda la documentacion la idea es dejarla alli, con excepcion al readme del
proyecto.

Recuerda hazme un plan de accion y bien estructurado, como si fuese un proyecto
enterprise, y profesional, profundiza en proyectos parecidos o similiares y el buen
uso de patrones y arquitecturas en terminos de desarrollo y de agentes
```

**Archivos le√≠dos**:
- `/home/jhonmo/apps/retos/ai-transactional-agent-fastapi/docs/CONTEXTO.md`
- `/home/jhonmo/apps/retos/ai-transactional-agent-fastapi/PRUEBA_TECNICA_AI_AGENT.md`
- `/home/jhonmo/apps/retos/ai-transactional-agent-fastapi/api-gabi-logic/` (varios archivos)

**Resultado**:
- An√°lisis completo de requerimientos
- Comparaci√≥n LangChain vs LangGraph
- Evaluaci√≥n del proyecto legacy (api-gabi-logic)
- Plan de 5 d√≠as con estructura detallada
- Arquitectura hexagonal propuesta
- Stack tecnol√≥gico moderno recomendado

**Tokens utilizados**: ~8,000 tokens (estimado, contexto amplio)

**Aprendizajes**:
- Proyecto legacy usa LangChain 0.0.330 (obsoleto)
- LangGraph es superior para agentes transaccionales
- Necesidad de patrones de resiliencia expl√≠citos
- Arquitectura hexagonal encaja perfectamente

---

#### 2.1.2 Refinamiento del Plan

**Fecha**: 2025-01-21
**Contexto**: Ajuste del plan inicial a 5 d√≠as de desarrollo

**Prompt**:
```
Pues la idea es testear muy bien todo, primero guardame el plan de trabajo y fases,
pero antes recuerda que tenemos 5 dias para poder realizar el proyecto por lo que
podemos estructuralo, organizarlo y testearlo correctamente, con las ultimas
caracteristicas usadas en el mercado laboral, ademas recuerda que en el requerimiento
piden explicitamente dejar registro de los prompts utilizados y demas, ademas tengo
al key de open ai, pero creo que es limitada, asi que primero voy a probar con claude,
dejar aparte los prompts o cosas que me genere uno vs otro
```

**Resultado**:
- Plan de trabajo extendido a 5 d√≠as (este documento)
- Estructura detallada d√≠a por d√≠a
- √ânfasis en testing (>70% coverage)
- Sistema de tracking de prompts (este archivo)
- Estrategia de uso: Claude para dev, OpenAI para producci√≥n

**Tokens utilizados**: ~12,000 tokens (incluyendo generaci√≥n del plan)

**Decisiones tomadas**:
1. Usar Claude para desarrollo asistido
2. Usar OpenAI gpt-4.1-mini para producci√≥n
3. Documentar TODOS los prompts en este archivo
4. Crear estructura de tracking separada por LLM

---

### 2.2 Dise√±o de Arquitectura

#### 2.2.1 [A completar durante el desarrollo]

**Fecha**: [Pendiente]
**Contexto**: [Descripci√≥n]
**Prompt**:
```
[Prompt exacto]
```
**Resultado**: [Descripci√≥n]
**Tokens**: [Estimado]

---

### 2.3 Implementaci√≥n de Componentes

#### 2.3.1 [A completar durante el desarrollo]

**Fecha**: [Pendiente]
**Contexto**: [Descripci√≥n]
**Prompt**:
```
[Prompt exacto]
```
**Resultado**: [Descripci√≥n]
**Tokens**: [Estimado]

---

### 2.4 Debugging y Optimizaci√≥n

#### 2.4.1 [A completar durante el desarrollo]

**Fecha**: [Pendiente]
**Contexto**: [Descripci√≥n]
**Prompt**:
```
[Prompt exacto]
```
**Resultado**: [Descripci√≥n]
**Tokens**: [Estimado]

---

### 2.5 Refactoring y Code Review

#### 2.5.1 [A completar durante el desarrollo]

**Fecha**: [Pendiente]
**Contexto**: [Descripci√≥n]
**Prompt**:
```
[Prompt exacto]
```
**Resultado**: [Descripci√≥n]
**Tokens**: [Estimado]

---

## 3. Prompts del Sistema - OpenAI {#prompts-sistema-openai}

> **Nota**: Estos prompts se ejecutan en producci√≥n y consumen la API Key proporcionada.
> **CR√çTICO**: Optimizar para minimizar consumo de tokens (l√≠mite 100K).

### 3.1 System Prompts

#### 3.1.1 System Prompt Principal del Agente

**Versi√≥n**: 1.0.0
**Fecha creaci√≥n**: [A definir]
**Modelo**: gpt-4.1-mini
**Temperatura**: 0
**Max tokens respuesta**: 500

**Prompt**:
```python
SYSTEM_PROMPT_V1 = """
Eres un asistente bancario amigable y profesional especializado en procesar
env√≠os de dinero en Colombia.

## Tu Objetivo
Extraer la siguiente informaci√≥n del usuario de forma conversacional:
1. N√∫mero de tel√©fono del destinatario (10 d√≠gitos)
2. Monto a enviar (en pesos colombianos, debe ser mayor a 0)

## Reglas Importantes
- S√© conciso y claro. M√°ximo 2-3 oraciones por respuesta.
- NO hagas suposiciones sobre datos no proporcionados
- Si falta informaci√≥n, pregunta UNA cosa a la vez
- Valida el formato antes de pedir confirmaci√≥n
- Maneja errores con empat√≠a y claridad

## Validaciones
- Tel√©fono: Exactamente 10 d√≠gitos, comenzando con 3
- Monto: N√∫mero positivo mayor a 0

## Formato de Respuesta
- Tono: Profesional pero amigable
- Longitud: Concisa (2-3 oraciones)
- No uses emojis
- Confirma los datos antes de proceder

## Ejemplos de Interacci√≥n
User: "Quiero enviar dinero"
Assistant: "Con gusto te ayudo. ¬øA qu√© n√∫mero de celular deseas enviar el dinero?"

User: "Al 3001234567"
Assistant: "Perfecto, 3001234567. ¬øQu√© monto deseas enviar?"

User: "50000 pesos"
Assistant: "Entendido. Confirmas el env√≠o de $50,000 COP al n√∫mero 3001234567?
Responde 'S√≠, confirmo' para proceder o 'No' para cancelar."

## Manejo de Errores
- Tel√©fono inv√°lido: "El n√∫mero debe tener 10 d√≠gitos y comenzar con 3.
  ¬øPodr√≠as verificarlo?"
- Monto inv√°lido: "El monto debe ser mayor a 0. ¬øCu√°nto deseas enviar?"
"""
```

**Estimaci√≥n de tokens**: ~350 tokens

**Justificaci√≥n del dise√±o**:
- Estructura clara con secciones
- Ejemplos concretos para few-shot learning
- Validaciones expl√≠citas
- Manejo de errores predefinido
- Longitud controlada para reducir tokens

**Iteraciones**:
- v1.0.0: Versi√≥n inicial

---

#### 3.1.2 Prompt de Extracci√≥n Estructurada

**Versi√≥n**: 1.0.0
**Fecha creaci√≥n**: [A definir]
**Modelo**: gpt-4.1-mini
**Uso**: Function calling para extraer datos

**Funci√≥n Definida**:
```python
EXTRACTION_FUNCTION = {
    "name": "extract_transaction_info",
    "description": "Extrae informaci√≥n de transacci√≥n del mensaje del usuario",
    "parameters": {
        "type": "object",
        "properties": {
            "recipient_phone": {
                "type": "string",
                "description": "N√∫mero de tel√©fono de 10 d√≠gitos, solo n√∫meros",
                "pattern": "^3[0-9]{9}$"
            },
            "amount": {
                "type": "number",
                "description": "Monto a enviar en pesos colombianos, debe ser mayor a 0",
                "minimum": 1
            },
            "confidence": {
                "type": "string",
                "enum": ["high", "medium", "low"],
                "description": "Confianza en la extracci√≥n"
            }
        }
    }
}
```

**Prompt de contexto para function calling**:
```python
EXTRACTION_CONTEXT = """
Del mensaje del usuario, extrae la informaci√≥n disponible.
Si un campo no est√° presente o no est√°s seguro, devuelve null.

Reglas de parsing:
- Tel√©fono: Normaliza removiendo espacios, guiones, par√©ntesis
  Ejemplos: "300-123-4567" ‚Üí "3001234567", "300 123 4567" ‚Üí "3001234567"
- Monto: Acepta formatos como "50000", "50 mil", "cincuenta mil"
  Conversiones: "mil" = 1000, "mill√≥n" = 1000000
- Confidence:
  - high: Datos claros y validables
  - medium: Datos presentes pero ambiguos
  - low: Datos posiblemente incorrectos

NO inventes datos. Si hay duda, marca confidence como "low".
"""
```

**Estimaci√≥n de tokens**: ~200 tokens

**Ventajas del approach**:
- Function calling reduce tokens vs parsing manual
- Respuestas estructuradas (JSON)
- Validaci√≥n autom√°tica de tipos
- Confianza expl√≠cita

---

#### 3.1.3 Prompt de Confirmaci√≥n

**Versi√≥n**: 1.0.0
**Fecha creaci√≥n**: [A definir]
**Modelo**: gpt-4.1-mini
**Uso**: Generar mensaje de confirmaci√≥n

**Template**:
```python
CONFIRMATION_TEMPLATE = """
Genera un mensaje de confirmaci√≥n profesional y claro para una transacci√≥n de
env√≠o de dinero con los siguientes datos:

- N√∫mero destinatario: {recipient_phone}
- Monto: ${amount:,.0f} COP

Requisitos:
1. Confirma los datos de forma clara
2. Pide confirmaci√≥n expl√≠cita
3. Menciona las opciones: "S√≠, confirmo" o "No, cancelar"
4. M√°ximo 2-3 oraciones
5. Tono profesional pero amigable

NO agregues informaci√≥n adicional como comisiones o tiempos (eso no es parte
del scope).
"""
```

**Ejemplo de output esperado**:
```
"Entendido. Confirmas el env√≠o de $50,000 COP al n√∫mero 3001234567?
Por favor responde 'S√≠, confirmo' para proceder o 'No' para cancelar la operaci√≥n."
```

**Estimaci√≥n de tokens**: ~150 tokens (template) + ~50 tokens (output)

---

### 3.2 Prompts para Manejo de Errores

#### 3.2.1 Prompt para Errores de Validaci√≥n

**Versi√≥n**: 1.0.0
**Fecha creaci√≥n**: [A definir]

**Template**:
```python
ERROR_HANDLING_PROMPT = """
El usuario proporcion√≥ datos inv√°lidos. Genera un mensaje de error amigable.

Error: {error_type}
Valor proporcionado: {provided_value}
Expectativa: {expected_format}

Requisitos:
1. Explica el error de forma clara y simple
2. Indica qu√© se esperaba
3. Pide que lo intente de nuevo
4. Mant√©n tono emp√°tico (no culpes al usuario)
5. M√°ximo 2 oraciones

Tipos de error:
- invalid_phone: Tel√©fono no tiene 10 d√≠gitos o no empieza con 3
- invalid_amount: Monto es 0, negativo o no es un n√∫mero
- missing_data: Falta informaci√≥n requerida
"""
```

**Ejemplos de outputs**:
```python
# invalid_phone
"El n√∫mero debe tener 10 d√≠gitos y comenzar con 3. ¬øPodr√≠as verificar el n√∫mero?"

# invalid_amount
"El monto debe ser mayor a 0. ¬øCu√°nto deseas enviar?"

# missing_data
"Para completar el env√≠o necesito el n√∫mero del destinatario. ¬øA qu√© n√∫mero
deseas enviar?"
```

**Estimaci√≥n de tokens**: ~100 tokens (template) + ~40 tokens (output)

---

#### 3.2.2 Prompt para Fallos de API Externa

**Versi√≥n**: 1.0.0
**Fecha creaci√≥n**: [A definir]

**Template**:
```python
API_ERROR_PROMPT = """
Ocurri√≥ un error al procesar la transacci√≥n con el servicio externo.

Error t√©cnico: {technical_error}
Acci√≥n que se intent√≥: {action}

Genera un mensaje para el usuario que:
1. Explique que hubo un problema temporal
2. NO revele detalles t√©cnicos
3. Indique qu√© puede hacer (reintentar, esperar, contactar soporte)
4. Mantenga la calma y profesionalismo
5. M√°ximo 2 oraciones

El usuario NO debe ver el error t√©cnico.
"""
```

**Ejemplos de outputs**:
```python
# Timeout
"Lo siento, hubo un problema temporal al procesar tu solicitud.
¬øPodr√≠as intentarlo nuevamente?"

# Service unavailable
"El servicio de transacciones est√° temporalmente no disponible.
Por favor intenta en unos minutos."

# Circuit breaker open
"Estamos experimentando problemas t√©cnicos temporales.
Por favor intenta m√°s tarde o contacta a soporte."
```

**Estimaci√≥n de tokens**: ~120 tokens (template) + ~50 tokens (output)

---

### 3.3 Prompts para Features Avanzados (Opcional)

#### 3.3.1 Prompt para Detecci√≥n de Intenci√≥n

**Versi√≥n**: 1.0.0
**Fecha creaci√≥n**: [A definir]
**Uso**: Clasificar intenci√≥n del usuario (opcional, si sobra presupuesto de tokens)

**Prompt**:
```python
INTENT_CLASSIFICATION_PROMPT = """
Clasifica la intenci√≥n del usuario en UNA de las siguientes categor√≠as:

Categor√≠as:
- start_transaction: Quiere iniciar un env√≠o de dinero
- provide_phone: Est√° dando el n√∫mero de tel√©fono
- provide_amount: Est√° dando el monto
- confirm: Est√° confirmando la transacci√≥n
- cancel: Quiere cancelar
- ask_status: Pregunta por el estado de una transacci√≥n
- help: Pide ayuda o informaci√≥n
- out_of_scope: Mensaje fuera del alcance del sistema

Mensaje del usuario: {user_message}

Responde SOLO con la categor√≠a, sin explicaci√≥n.
"""
```

**Nota**: Este prompt es OPCIONAL y solo se usar√≠a si tenemos presupuesto de tokens
sobrante. La extracci√≥n con function calling ya maneja la mayor√≠a de casos.

**Estimaci√≥n de tokens**: ~150 tokens (probablemente no se use)

---

## 4. Comparaci√≥n y An√°lisis {#comparaci√≥n-y-an√°lisis}

### 4.1 Claude vs OpenAI: Caracter√≠sticas

| Aspecto | Claude (Anthropic) | OpenAI |
|---------|-------------------|---------|
| **Contexto** | 200K tokens | 128K tokens (gpt-4.1-mini) |
| **Costo** | ~$3/M tokens input | ~$0.15/M tokens (mini) |
| **Velocidad** | Moderada | R√°pida |
| **Function calling** | Limitado | Excelente |
| **Razonamiento** | Excelente | Muy bueno |
| **Disponibilidad API** | Limited preview | GA (Generally Available) |
| **Rate limits** | M√°s restrictivos | Generosos |

### 4.2 Decisi√≥n de Uso

#### Para Desarrollo (Claude)

**‚úÖ Usar Claude para**:
- Dise√±o de arquitectura
- Refactoring de c√≥digo
- Explicaciones detalladas
- Generaci√≥n de documentaci√≥n
- Code review
- Debugging complejo

**Justificaci√≥n**:
- Contexto amplio permite entender todo el proyecto
- Excelente para razonamiento arquitect√≥nico
- No consume API Key de OpenAI (limitada)

#### Para Producci√≥n (OpenAI)

**‚úÖ Usar OpenAI gpt-4.1-mini para**:
- Procesamiento de mensajes del usuario
- Extracci√≥n de informaci√≥n
- Generaci√≥n de respuestas
- Clasificaci√≥n de intenciones

**Justificaci√≥n**:
1. API Key proporcionada por el evaluador
2. gpt-4.1-mini es 10x m√°s barato que gpt-4
3. Function calling robusto y confiable
4. Suficiente para el scope del agente
5. Rate limits adecuados para la prueba

### 4.3 ¬øPor qu√© NO gpt-4.1-nano?

Aunque gpt-4.1-nano es a√∫n m√°s barato:
- ‚ùå Menos capacidad de razonamiento
- ‚ùå Contexto m√°s limitado (64K)
- ‚ùå Peor performance en extracci√≥n compleja

**Decisi√≥n**: gpt-4.1-mini ofrece mejor balance precio/calidad para este caso de uso.

---

## 5. Optimizaciones de Tokens {#optimizaciones-de-tokens}

### 5.1 L√≠mite de Tokens

**Disponible**: 100,000 tokens totales
**Estrategia**: Usar de forma conservadora

### 5.2 Estrategias de Optimizaci√≥n Implementadas

#### 5.2.1 Truncado de Historial

```python
# Implementaci√≥n en c√≥digo
MAX_MESSAGES_IN_HISTORY = 10  # √öltimos 10 mensajes solamente

def truncate_conversation_history(messages: list) -> list:
    """
    Mantiene solo los √∫ltimos N mensajes para reducir tokens.
    System prompt + √∫ltimos 10 mensajes usuario/asistente.
    """
    if len(messages) <= MAX_MESSAGES_IN_HISTORY:
        return messages

    # Siempre mantener el system prompt
    system_messages = [m for m in messages if m["role"] == "system"]
    other_messages = [m for m in messages if m["role"] != "system"]

    # √öltimos N mensajes
    recent_messages = other_messages[-MAX_MESSAGES_IN_HISTORY:]

    return system_messages + recent_messages
```

**Ahorro**: ~50% de tokens en conversaciones largas

---

#### 5.2.2 Summarization de Conversaciones Largas

```python
# Si conversaci√≥n > 20 mensajes, resumir los primeros 10
MAX_BEFORE_SUMMARIZATION = 20

def maybe_summarize_conversation(messages: list) -> list:
    """
    Si hay m√°s de 20 mensajes, resume los primeros 10 en un solo mensaje.
    """
    if len(messages) <= MAX_BEFORE_SUMMARIZATION:
        return messages

    messages_to_summarize = messages[:10]
    recent_messages = messages[10:]

    # Usar gpt-4.1-mini para resumir (m√°s barato)
    summary = summarize_messages(messages_to_summarize)

    return [
        {"role": "system", "content": f"Resumen de conversaci√≥n previa: {summary}"}
    ] + recent_messages
```

**Ahorro**: ~60% de tokens en conversaciones muy largas (>20 mensajes)

---

#### 5.2.3 System Prompt Conciso

- ‚ùå **Evitar**: Ejemplos exhaustivos, repeticiones, explicaciones largas
- ‚úÖ **Preferir**: Bullets, secciones claras, ejemplos m√≠nimos

**Comparaci√≥n**:
```python
# ‚ùå Prompt verbose (500 tokens)
VERBOSE_PROMPT = """
Eres un asistente muy amigable y servicial que trabaja para un banco...
[muchas explicaciones repetitivas]
"""

# ‚úÖ Prompt conciso (350 tokens)
CONCISE_PROMPT = """
Eres un asistente bancario que procesa env√≠os de dinero.

Objetivo: Extraer tel√©fono (10 d√≠gitos) y monto (>0).
Reglas: Conciso, sin suposiciones, valida datos.
"""
```

**Ahorro**: 30% en system prompt

---

#### 5.2.4 Function Calling vs Text Parsing

```python
# ‚ùå Parsing de texto (consume m√°s tokens)
response = llm.invoke(
    "Extrae el tel√©fono y monto del siguiente texto: ..."
)
# Respuesta: "El tel√©fono es 3001234567 y el monto es 50000" (m√°s tokens)

# ‚úÖ Function calling (estructurado, menos tokens)
response = llm.invoke(
    messages,
    functions=[extract_transaction_info]
)
# Respuesta: {"recipient_phone": "3001234567", "amount": 50000} (menos tokens)
```

**Ahorro**: ~40% en respuestas estructuradas

---

### 5.3 M√©tricas de Consumo

#### Estimaci√≥n por Conversaci√≥n Completa

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CONVERSACI√ìN COMPLETA (5 turnos usuario/asistente) ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  System prompt:            350 tokens               ‚îÇ
‚îÇ  Historial (10 msgs):      400 tokens               ‚îÇ
‚îÇ  User input (promedio):     30 tokens x 5 = 150     ‚îÇ
‚îÇ  Assistant output:         200 tokens x 5 = 1000    ‚îÇ
‚îÇ  Function calls:           100 tokens x 3 = 300     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  TOTAL POR CONVERSACI√ìN:  ~2,200 tokens             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Con 100,000 tokens disponibles:
- Conversaciones completas posibles: ~45
- Margen de seguridad (20%): ~36 conversaciones
```

#### Alertas de Consumo

Implementar alertas cuando se alcance:

```python
TOKEN_ALERTS = {
    "warning": 50_000,   # 50% consumido
    "critical": 75_000,  # 75% consumido
    "emergency": 90_000  # 90% consumido
}

def check_token_usage(tokens_used: int):
    if tokens_used >= TOKEN_ALERTS["emergency"]:
        log.error("EMERGENCY: 90% tokens consumidos")
        # Considerar desactivar features opcionales
    elif tokens_used >= TOKEN_ALERTS["critical"]:
        log.warning("CRITICAL: 75% tokens consumidos")
    elif tokens_used >= TOKEN_ALERTS["warning"]:
        log.info("WARNING: 50% tokens consumidos")
```

---

#### Monitoreo en Tiempo Real

```python
# Implementar endpoint de m√©tricas
@app.get("/api/v1/metrics/tokens")
async def get_token_metrics():
    return {
        "total_available": 100_000,
        "total_used": get_tokens_used_from_db(),
        "remaining": 100_000 - get_tokens_used_from_db(),
        "percentage_used": (get_tokens_used_from_db() / 100_000) * 100,
        "estimated_conversations_remaining": (100_000 - get_tokens_used_from_db()) / 2200
    }
```

---

### 5.4 Plan B: Si se Agotan los Tokens

Si nos quedamos sin tokens de OpenAI:

1. **Opci√≥n 1**: Usar Claude API (si est√° disponible)
   - Requiere API key propia
   - M√°s caro pero funcional

2. **Opci√≥n 2**: Usar modelos locales
   - Llama 3.1 (8B) v√≠a Ollama
   - Gratis pero requiere ajustar prompts
   - Menor calidad

3. **Opci√≥n 3**: Mocks para tests
   - Respuestas predefinidas
   - Solo para demostraci√≥n
   - NO recomendado (no es funcional)

**Prioridad**: Optimizar para NO tener que usar Plan B.

---

## 6. Versionado de Prompts {#versionado-de-prompts}

### 6.1 Estrategia de Versionado

Todos los prompts siguen semantic versioning: `MAJOR.MINOR.PATCH`

- **MAJOR**: Cambios que rompen compatibilidad (cambio de estructura)
- **MINOR**: Agregar funcionalidad (nuevas secciones, ejemplos)
- **PATCH**: Correcciones menores (typos, optimizaciones)

### 6.2 Historial de Versiones

#### System Prompt Principal

| Versi√≥n | Fecha | Cambios | Impacto Tokens | Raz√≥n |
|---------|-------|---------|----------------|-------|
| 1.0.0 | [TBD] | Versi√≥n inicial | Baseline | Implementaci√≥n inicial |

*(Se actualizar√° durante el desarrollo)*

---

#### Prompt de Extracci√≥n

| Versi√≥n | Fecha | Cambios | Impacto Tokens | Raz√≥n |
|---------|-------|---------|----------------|-------|
| 1.0.0 | [TBD] | Versi√≥n inicial | Baseline | Implementaci√≥n inicial |

*(Se actualizar√° durante el desarrollo)*

---

### 6.3 Testing de Prompts

Cada versi√≥n de prompt debe probarse con:

```python
# tests/prompts/test_system_prompt.py

PROMPT_TEST_CASES = [
    {
        "user_message": "Quiero enviar dinero",
        "expected_intent": "start_transaction",
        "expected_asks_for": "phone"
    },
    {
        "user_message": "Al 3001234567",
        "expected_extraction": {"recipient_phone": "3001234567"},
        "expected_asks_for": "amount"
    },
    {
        "user_message": "50000 pesos",
        "expected_extraction": {"amount": 50000},
        "expected_asks_for": "confirmation"
    },
    {
        "user_message": "S√≠ confirmo",
        "expected_action": "execute_transaction"
    }
]

def test_prompt_consistency():
    """Verifica que el prompt produce resultados consistentes"""
    for test_case in PROMPT_TEST_CASES:
        # Ejecutar 5 veces el mismo prompt
        results = [
            run_prompt(test_case["user_message"])
            for _ in range(5)
        ]
        # Verificar consistencia >80%
        assert consistency_score(results) > 0.8
```

---

## 7. Ap√©ndices {#ap√©ndices}

### Ap√©ndice A: Ejemplos de Conversaciones Completas

#### A.1 Flujo Exitoso

```
[SYSTEM]: [System prompt v1.0.0]

[USER]: Hola, quiero enviar dinero

[ASSISTANT]: Con gusto te ayudo. ¬øA qu√© n√∫mero de celular deseas enviar el dinero?

[USER]: Al 3001234567

[ASSISTANT]: Perfecto, 3001234567. ¬øQu√© monto deseas enviar?

[USER]: 50000 pesos

[ASSISTANT]: Entendido. Confirmas el env√≠o de $50,000 COP al n√∫mero 3001234567?
Responde 'S√≠, confirmo' para proceder o 'No' para cancelar.

[USER]: S√≠, confirmo

[ASSISTANT]: Transacci√≥n completada exitosamente. El ID de tu transacci√≥n es:
TXN-20250121143022-4582. Hemos enviado $50,000 COP al n√∫mero 3001234567.

[TOKENS ESTIMADOS]: ~2,100 tokens
```

---

#### A.2 Manejo de Error: Tel√©fono Inv√°lido

```
[SYSTEM]: [System prompt v1.0.0]

[USER]: Quiero enviar plata

[ASSISTANT]: Con gusto. ¬øA qu√© n√∫mero de celular deseas enviar el dinero?

[USER]: Al 123456

[ASSISTANT]: El n√∫mero debe tener 10 d√≠gitos y comenzar con 3. ¬øPodr√≠as verificarlo?

[USER]: Perd√≥n, es 3001234567

[ASSISTANT]: Perfecto, 3001234567. ¬øQu√© monto deseas enviar?

[TOKENS ESTIMADOS]: ~1,800 tokens
```

---

#### A.3 Cancelaci√≥n de Usuario

```
[SYSTEM]: [System prompt v1.0.0]

[USER]: Quiero enviar dinero

[ASSISTANT]: Con gusto te ayudo. ¬øA qu√© n√∫mero de celular deseas enviar el dinero?

[USER]: Al 3001234567

[ASSISTANT]: Perfecto, 3001234567. ¬øQu√© monto deseas enviar?

[USER]: 100000 pesos

[ASSISTANT]: Entendido. Confirmas el env√≠o de $100,000 COP al n√∫mero 3001234567?
Responde 'S√≠, confirmo' para proceder o 'No' para cancelar.

[USER]: No, mejor no

[ASSISTANT]: Entendido, he cancelado la transacci√≥n. ¬øHay algo m√°s en lo que
pueda ayudarte?

[TOKENS ESTIMADOS]: ~2,000 tokens
```

---

### Ap√©ndice B: Herramientas de Monitoreo

#### B.1 Script de Conteo de Tokens

```python
# scripts/count_tokens.py

import tiktoken

def count_tokens(text: str, model: str = "gpt-4") -> int:
    """Cuenta tokens para un texto dado"""
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))

def estimate_conversation_cost(messages: list) -> dict:
    """Estima costo de una conversaci√≥n"""
    total_tokens = sum(count_tokens(m["content"]) for m in messages)

    # Precios gpt-4.1-mini (input)
    cost_per_million = 0.15
    cost = (total_tokens / 1_000_000) * cost_per_million

    return {
        "total_tokens": total_tokens,
        "estimated_cost_usd": cost,
        "remaining_budget": 100_000 - total_tokens
    }
```

---

#### B.2 Dashboard de M√©tricas

```python
# src/api/routes/monitoring.py

@app.get("/monitoring/prompts")
async def get_prompt_metrics():
    """Dashboard de uso de prompts"""
    return {
        "prompts": {
            "system_prompt": {
                "version": "1.0.0",
                "tokens": 350,
                "usage_count": get_usage_count("system_prompt")
            },
            "extraction_prompt": {
                "version": "1.0.0",
                "tokens": 200,
                "usage_count": get_usage_count("extraction_prompt")
            }
        },
        "global_metrics": {
            "total_tokens_used": get_total_tokens(),
            "total_conversations": get_conversation_count(),
            "avg_tokens_per_conversation": get_avg_tokens(),
            "budget_remaining_percentage": get_budget_percentage()
        }
    }
```

---

### Ap√©ndice C: Checklist de Prompts

Antes de deployar un nuevo prompt:

- [ ] Testeado con al menos 10 casos de prueba
- [ ] Medido consumo de tokens
- [ ] Documentado en este archivo
- [ ] Versionado correctamente
- [ ] Comparado con versi√≥n anterior (si aplica)
- [ ] Revisado por al menos una persona
- [ ] Incluido en suite de tests autom√°ticos

---

### Ap√©ndice D: Referencias y Recursos

#### Documentaci√≥n Oficial

- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)
- [Tiktoken (token counting)](https://github.com/openai/tiktoken)
- [Best Practices for Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)

#### Art√≠culos y Papers

- [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903)
- [Constitutional AI](https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback)

---

## üìù Notas Finales

### Sobre Este Documento

Este documento es **OBLIGATORIO** seg√∫n los requerimientos de la prueba t√©cnica.
Se actualiza continuamente durante el desarrollo del proyecto.

### C√≥mo Contribuir

Durante el desarrollo, cada vez que uses un prompt:

1. Agrega una entrada en la secci√≥n correspondiente
2. Incluye contexto, prompt completo, y resultado
3. Estima tokens consumidos
4. Documenta decisiones tomadas

### Versionado del Documento

- **Versi√≥n actual**: 1.0.0
- **√öltima actualizaci√≥n**: 2025-01-21
- **Pr√≥xima revisi√≥n**: Al finalizar D√≠a 1

---

**Fin del documento**
